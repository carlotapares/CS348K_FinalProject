{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0840c03",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m optim, nn\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m models, transforms\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import optim, nn\n",
    "from torchvision import models, transforms\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5d140fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db2f58ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/lianapatel/Git/cs348k/CS348K_FinalProject/src', '/Library/Frameworks/Python.framework/Versions/3.8/lib/python38.zip', '/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8', '/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/lib-dynload', '', '/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages', '/Users/lianapatel/Git/bls']\n"
     ]
    }
   ],
   "source": [
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1ce95b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ui_utils import Condition, get_dataset_subset, check_assertions\n",
    "\n",
    "DATASET_PATH = './dataset/'\n",
    "res, dataset = get_dataset_subset(DATASET_PATH + 'wimbledon_2019_womens_final_halep_williams__fduc5bZx3ss',\n",
    "    ['fast', 'player_back'],5, 10, False)\n",
    "\n",
    "assertions = [{'keypoints': ['right_elbow','right_shoulder','right_wrist', 'right_shoulder'], 'type': 'spatial', 'attributes': ['above', 'above']}, \\\n",
    "              {'keypoints': ['left_shoulder','right_shoulder','left_knee', 'right_knee', 'left_hip', 'right_hip'], 'type': 'spatial', 'attributes': ['left', 'left', 'left']}, \\\n",
    "              {'keypoints': ['left_shoulder','right_shoulder','left_knee', 'right_knee', 'left_hip', 'right_hip'], 'type': 'spatial', 'attributes': ['right', 'right', 'right']}, \\\n",
    "              {'keypoints': ['left_elbow','right_elbow','left_wrist','right_wrist'], 'type': 'spatial', 'attributes': [('smaller', 0.05),('smaller', 0.15)]}, \\\n",
    "              {'keypoints': ['left_ankle','right_ankle','left_knee','right_knee'], 'type': 'spatial', 'attributes': [('smaller', 0.05),('smaller', 0.15)]}, \\\n",
    "              {'keypoints': ['head_top','head_bottom'], 'type': 'spatial', 'attributes': [('smaller', 0.25)]}, \\\n",
    "              {'keypoints': ['right_wrist'], 'type': 'temporal', 'attributes': [0.3]},\n",
    "              {'keypoints': ['left_wrist'], 'type': 'temporal', 'attributes': [0.3]}]\n",
    "\n",
    "errors, frames = check_assertions(DATASET_PATH + 'wimbledon_2019_womens_final_halep_williams__fduc5bZx3ss', dataset, res, assertions, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bff0a7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list = [f.get_data() for f in frames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2bf52585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.BytesIO at 0x1716667c0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# image_list = [] # TODO get from frames returned in check_assertion\n",
    "image_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ed26ee64",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'models' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mmodels\u001b[49m\u001b[38;5;241m.\u001b[39mvgg16(pretrained\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'models' is not defined"
     ]
    }
   ],
   "source": [
    "model = models.vgg16(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1c658139",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor(nn.Module):\n",
    "  def __init__(self, model):\n",
    "    super(FeatureExtractor, self).__init__()\n",
    "    # Extract VGG-16 Feature Layers\n",
    "    self.features = list(model.features)\n",
    "    self.features = nn.Sequential(*self.features)\n",
    "    # Extract VGG-16 Average Pooling Layer\n",
    "    self.pooling = model.avgpool\n",
    "    # Convert the image into one-dimensional vector\n",
    "    self.flatten = nn.Flatten()\n",
    "    # Extract the first part of fully-connected layer from VGG16\n",
    "    self.fc = model.classifier[0]\n",
    "  \n",
    "  def forward(self, x):\n",
    "    # It will take the input 'x' until it returns the feature vector called 'out'\n",
    "    out = self.features(x)\n",
    "    out = self.pooling(out)\n",
    "    out = self.flatten(out)\n",
    "    out = self.fc(out) \n",
    "    return out \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d68fec58",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'models' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [25]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Initialize the model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mmodels\u001b[49m\u001b[38;5;241m.\u001b[39mvgg16(pretrained\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m new_model \u001b[38;5;241m=\u001b[39m FeatureExtractor(model)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Change the device to GPU\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'models' is not defined"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "model = models.vgg16(pretrained=True)\n",
    "new_model = FeatureExtractor(model)\n",
    "\n",
    "# Change the device to GPU if avaialble\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\")\n",
    "new_model = new_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68cf378",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "626f80bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "TabError",
     "evalue": "inconsistent use of tabs and spaces in indentation (3287425015.py, line 20)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [26]\u001b[0;36m\u001b[0m\n\u001b[0;31m    img = cv2.imread(path)\u001b[0m\n\u001b[0m                          ^\u001b[0m\n\u001b[0;31mTabError\u001b[0m\u001b[0;31m:\u001b[0m inconsistent use of tabs and spaces in indentation\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# Transform the image, so it becomes readable with the model\n",
    "transform = transforms.Compose([\n",
    "  transforms.ToPILImage(),\n",
    "  transforms.CenterCrop(512),\n",
    "  transforms.Resize(448),\n",
    "  transforms.ToTensor()                              \n",
    "])\n",
    "\n",
    "# Will contain the feature\n",
    "features = []\n",
    "\n",
    "# Iterate each image\n",
    "for data in tqdm(image_list):\n",
    "    \n",
    "    # Transform the image\n",
    "    img = transform(data)\n",
    "    \n",
    "    # Reshape the image. PyTorch model reads 4-dimensional tensor\n",
    "    # [batch_size, channels, width, height]\n",
    "    img = img.reshape(1, 3, 448, 448)\n",
    "    img = img.to(device)\n",
    "    \n",
    "    \n",
    "    with torch.no_grad(): \n",
    "        feature = new_model(img) # Extract the feature from the image\n",
    "        \n",
    "    # Convert to NumPy Array, Reshape it, and save it to features variable\n",
    "    features.append(feature.cpu().detach().numpy().reshape(-1))\n",
    "\n",
    "# Convert to NumPy Array\n",
    "features = np.array(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620f4800",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4e2d0ab6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [28]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m KMeans(n_clusters\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Fit the data into the model\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(\u001b[43mfeatures\u001b[49m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Extract the labels\u001b[39;00m\n\u001b[1;32m     10\u001b[0m labels \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mlabels_\n",
      "\u001b[0;31mNameError\u001b[0m: name 'features' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Initialize the model\n",
    "model = KMeans(n_clusters=5, random_state=42)\n",
    "\n",
    "# Fit the data into the model\n",
    "model.fit(features)\n",
    "\n",
    "# Extract the labels\n",
    "labels = model.labels_\n",
    "\n",
    "print(labels) # [4 3 3 ... 0 0 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfc512a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
